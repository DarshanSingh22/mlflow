{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15ff9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ace9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT=\"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH=os.path.join(\"datasets\",\"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT+\"datasets/housing/housing.tgz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "726717d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path,\"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url,tgz_path)\n",
    "    housing_tgz= tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "448d6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5904c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path=os.path.join(housing_path,\"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435165e",
   "metadata": {},
   "source": [
    "### Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d3ac8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratified shuffle split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "349ae177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(test_size,housing):\n",
    "    split = StratifiedShuffleSplit(n_splits=1,test_size=test_size,random_state=42)\n",
    "    for train_index,test_index in split.split(housing,housing['income_cat']):\n",
    "        train_set=housing.loc[train_index]\n",
    "        test_set = housing.loc[test_index]\n",
    "    housing.drop('income_cat',axis=1,inplace=True)    \n",
    "    train_set_labels = train_set['median_house_value']\n",
    "    test_set_labels = test_set['median_house_value']\n",
    "    test_set.drop({'income_cat','median_house_value'},axis=1,inplace=True)\n",
    "    train_set.drop({'income_cat','median_house_value'},axis=1,inplace=True) \n",
    "\n",
    "    return train_set,test_set,train_set_labels,test_set_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9d7f6",
   "metadata": {},
   "source": [
    "#### How to define your own transformer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a69741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8dac72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseEstimator gives two functions get_params(),set_params()\n",
    "# TransformerMaxin can be used to mix two functions like fit() and transform() into fit_tranform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a41df313",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_ix,bedrooms_ix,population_ix,household_ix = 3,4,5,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3cb4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttributeAdder(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,add_bedrooms_per_room=True):     #no *args or **kargs\n",
    "        self.add_bedrooms_per_room=add_bedrooms_per_room\n",
    "    def fit(self,X,y=None):\n",
    "        return self \n",
    "    def transform(self,X,y=None):\n",
    "        rooms_per_household = X[:,rooms_ix]/X[:,household_ix]\n",
    "        population_per_household=X[:,population_ix]/X[:,population_ix]\n",
    "        if self.add_bedrooms_per_room :\n",
    "            bedrooms_per_room =X[:,rooms_ix]/X[:,household_ix]\n",
    "            return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n",
    "        else :\n",
    "            return np.c_[X,rooms_per_household,population_per_household]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f9fc1",
   "metadata": {},
   "source": [
    "### Transformation Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb439c08",
   "metadata": {},
   "source": [
    "#### Prepare the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36c107e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attr = list()\n",
    "cat_attr = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc09e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline=Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('attr_adder',CombinedAttributeAdder()),\n",
    "    ('std_scaler',StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a40fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling both the pipline simultaneously or joining the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72c848fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    ('num_pipeline',num_pipeline,num_attr),\n",
    "    (\"cat\",OneHotEncoder(),cat_attr)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427b7c3",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11069809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ea0bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ef05474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(actual, pred))\n",
    "    mae = metrics.mean_absolute_error(actual, pred)\n",
    "    r2 = metrics.r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bdc7ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://localhost:5000/\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9232de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5000/'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7702367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='House_price_pred', tags={}>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"House_price_pred\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "416cc202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(test_size):\n",
    "  \n",
    "    with mlflow.start_run(run_name='Parent_run') as parent_run:\n",
    "        #fetch the data\n",
    "        housing = load_housing_data()\n",
    "        \n",
    "        #data preparation\n",
    "        with mlflow.start_run(run_name='Child_run_1',nested=True) as child_run:\n",
    "            #creating a categorical median income column\n",
    "            housing['income_cat']=np.ceil(housing['median_income']/1.5)\n",
    "            housing['income_cat'].where(housing['median_income']<5,5.0,inplace=True)  #replace where the condition is false   \n",
    "            #split the data into train and test set\n",
    "            train_X,test_X,train_y,test_y = split_data(test_size,housing)\n",
    "            train_X_num = train_X.drop('ocean_proximity',axis=1)\n",
    "            num_attr = list(train_X_num)\n",
    "           \n",
    "        # Model training\n",
    "        with mlflow.start_run(run_name='Child_run_2',nested=True) as child_run:\n",
    "                train_set_prep=full_pipeline.fit_transform(train_X)\n",
    "                lin_reg = LinearRegression()\n",
    "                lin_reg = lin_reg.fit(train_set_prep,train_y)\n",
    "                \n",
    "        #Model Prediction and Evaluation \n",
    "        with mlflow.start_run(run_name='Child_run_3',nested=True) as child_run:\n",
    "                test_set_prep = full_pipeline.fit_transform(test_X)\n",
    "                predicted_ = lin_reg.predict(test_set_prep)\n",
    "                (rmse, mae, r2) = eval_metrics(test_y, predicted_)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        \n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_metric(key = 'test_size', value = test_size)\n",
    "        mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "        mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "       # mlflow.log_artifact(HOUSING_URL)\n",
    "         \n",
    "        mlflow.sklearn.log_model(lin_reg, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d89770d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RMSE: 99652.65788494414\n",
      "  MAE: 76285.36096105064\n",
      "  R2: 0.23938415279112402\n"
     ]
    }
   ],
   "source": [
    "train(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a6c7057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RMSE: 99005.48760241744\n",
      "  MAE: 75975.85514765118\n",
      "  R2: 0.24248016912926196\n"
     ]
    }
   ],
   "source": [
    "train(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e10964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
